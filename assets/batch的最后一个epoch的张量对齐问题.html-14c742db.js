import{_ as e,r as t,o,c as p,a as s,d as a,b as c,e as l}from"./app-04b0d2b0.js";const r={},i=l(`<h1 id="一个epoch前几个batch正常训练-最后一个batch的数据不足报错" tabindex="-1"><a class="header-anchor" href="#一个epoch前几个batch正常训练-最后一个batch的数据不足报错" aria-hidden="true">#</a> 一个Epoch前几个batch正常训练，最后一个batch的数据不足报错</h1><h2 id="问题" tabindex="-1"><a class="header-anchor" href="#问题" aria-hidden="true">#</a> 问题：</h2><p>在模型训练过程中，一个epoch的前几轮batch数据可以正常训练输出loss，在最后一轮batch数据报错，大概率就是数据量和epoch不匹配，导致最后一个batch的数据不能被整除，所以导致该问题。</p><h2 id="解决方案1" tabindex="-1"><a class="header-anchor" href="#解决方案1" aria-hidden="true">#</a> 解决方案1：</h2><p>手动将epoch的参数调整一下，保证num-data/ batchz-size= epoch中的所有参数均为整数。</p><h2 id="解决方案2" tabindex="-1"><a class="header-anchor" href="#解决方案2" aria-hidden="true">#</a> 解决方案2：</h2><p>删除最后一个batch的数据，不参与训练，具体的操作是在定义dataloader的时候，设置drop_last参数为True。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> batch_sampler<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> worker_init_fn<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> multiprocessing_context<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> generator<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">,</span> prefetch_factor<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> persistent_workers<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pin_memory_device<span class="token operator">=</span><span class="token string">&#39;&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="custom-container tip"><p class="custom-container-title">TIP</p><p>drop_last:设置为True表示在数据量与batch_size不能被整除的情况下，删除不完整的batch数据；默认设置为False drop_last (bool, optional) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)</p></div>`,9),h={href:"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader",target:"_blank",rel:"noopener noreferrer"};function u(d,k){const n=t("ExternalLinkIcon");return o(),p("div",null,[i,s("p",null,[a("参考官网定义："),s("a",h,[a("torch.utils.data — PyTorch 2.0 documentation"),c(n)]),a(" ———————————————— 版权声明：本文为CSDN博主「zy_destiny」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/qq_38308388/article/details/131041955")])])}const _=e(r,[["render",u],["__file","batch的最后一个epoch的张量对齐问题.html.vue"]]);export{_ as default};
