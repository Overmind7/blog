import{_ as o,r as p,o as c,c as i,a as n,d as s,b as e,e as t}from"./app-04b0d2b0.js";const l={},r=t(`<h1 id="常用函数" tabindex="-1"><a class="header-anchor" href="#常用函数" aria-hidden="true">#</a> 常用函数</h1><h2 id="torch-mean" tabindex="-1"><a class="header-anchor" href="#torch-mean" aria-hidden="true">#</a> torch.mean()</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>_VariableFunctions @overload <span class="token keyword">def</span> <span class="token function">mean</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span>
         dim<span class="token punctuation">:</span> Sequence<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> ellipsis<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         keepdim<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
         <span class="token operator">*</span><span class="token punctuation">,</span>
         dtype<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>dtype<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
         out<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>mean()函数的参数：</p><ul><li>dim=0,按行求平均值，返回的形状是（1，列数）；</li><li>dim=1,按列求平均值，返回的形状是（行数，1）,</li><li>默认不设置dim的时候，返回的是所有元素的平均值。</li></ul>`,5),u={href:"https://blog.csdn.net/u013049912/article/details/105628097",target:"_blank",rel:"noopener noreferrer"},d=t(`<h2 id="torch-split" tabindex="-1"><a class="header-anchor" href="#torch-split" aria-hidden="true">#</a> torch.split()</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> split_size_or_sections<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li><code>tensor</code>：要被切割的张量</li><li><code>split_size_or_sections</code>：当此参数为整数时，意思是将tensor按照每块大小为split_size_or_sections来切割，当此参数为列表时，将此tensor切成和列表中元素大小一样的大小的块。</li><li><code>dim</code>：指定要切割的维度</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> a<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>tensor([[0.7568, 0.6668, 0.8802, 0.5335, 0.1019],
        [0.4578, 0.9263, 0.9214, 0.5211, 0.5284],
        [0.8461, 0.5140, 0.8428, 0.4166, 0.5266],
        [0.1308, 0.4008, 0.2265, 0.0765, 0.2782]])
torch.Size([4, 2])
torch.Size([4, 2])
torch.Size([4, 1])
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,5),k={href:"https://blog.csdn.net/Fluid_ray/article/details/110873095",target:"_blank",rel:"noopener noreferrer"},h=n("h2",{id:"torch-sum",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#torch-sum","aria-hidden":"true"},"#"),s(" torch.sum()")],-1),m=n("h2",{id:"torch-matmul",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#torch-matmul","aria-hidden":"true"},"#"),s(" torch.matmul()")],-1);function v(b,_){const a=p("ExternalLinkIcon");return c(),i("div",null,[r,n("blockquote",null,[n("p",null,[n("a",u,[s("torch.mean"),e(a)])])]),d,n("blockquote",null,[n("p",null,[n("a",k,[s("tensor分割"),e(a)])])]),h,m])}const f=o(l,[["render",v],["__file","常用函数.html.vue"]]);export{f as default};
