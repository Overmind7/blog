import{_ as a,r as l,o as r,c as o,a as e,d as i,b as n,e as s}from"./app-04b0d2b0.js";const c={},h=e("h1",{id:"deblurring-via-stochastic-refinement",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#deblurring-via-stochastic-refinement","aria-hidden":"true"},"#"),i(" Deblurring via Stochastic Refinement")],-1),d=e("p",null,"(cvpr 2022')Deblurring via Stochastic Refinement",-1),m={href:"https://paperswithcode.com/paper/deblurring-via-stochastic-refinement",target:"_blank",rel:"noopener noreferrer"},u=e("p",null,"未开源",-1),g=e("h2",{id:"related-work",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#related-work","aria-hidden":"true"},"#"),i(" related work")],-1),p=e("ul",null,[e("li",null,"cvpr 18‘ the preception-distortion tradeoff"),e("li",null,"pd 曲线")],-1),_=e("img",{src:"https://raw.githubusercontent.com/Overmind7/images/main/image-20230321162647617.png",alt:"",style:{zoom:"50%"}},null,-1),b={href:"https://blog.csdn.net/gwplovekimi/article/details/84707451",target:"_blank",rel:"noopener noreferrer"},f=s('<h2 id="method" tabindex="-1"><a class="header-anchor" href="#method" aria-hidden="true">#</a> method</h2><ul><li>predict ＆ refine，扩散模型的 x0 不再是原图，而是原图和 predictor 的残差</li></ul><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311141615606.png" alt="image-20230311141615606"></p><ul><li>sample averaging：由于每一次采样的随机性，可以多重建几次，取平均</li><li>采样步数越多，主观质量越好，反之客观质量越好 <ul><li><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311142218597.png" alt="image-20230311142218597" style="zoom:50%;"></li></ul></li><li>训练的时候用小patch，测试的时候用整张图————low level task</li></ul><h2 id="网络架构" tabindex="-1"><a class="header-anchor" href="#网络架构" aria-hidden="true">#</a> 网络架构</h2><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311142928780.png" alt="image-20230311142928780"></p><ul><li>未开源</li><li>initial predictor 和 denoiser 是一样的，base channel 前者64，后者32</li><li>参数量前者 26m，后者7m</li></ul><h2 id="result" tabindex="-1"><a class="header-anchor" href="#result" aria-hidden="true">#</a> result</h2><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311143618168.png" alt="image-20230311143618168" style="zoom:67%;"><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311143702099.png" alt="image-20230311143702099" style="zoom:67%;"><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/image-20230311141651053.png" alt="image-20230311141651053"></p><blockquote><p>Low-level任务：常见的包括 Super-Resolution，denoise， deblur， dehze， low-light enhancement， deartifacts等。简单来说，是把特定降质下的图片还原成好看的图像，现在基本上用end-to-end的模型来学习这类 ill-posed问题的求解过程，客观指标主要是PSNR，SSIM，大家指标都刷的很高。目前面临以下几点问题：</p><ul><li>泛化性差，换个数据集，同种任务变现就很差</li><li>客观指标与主观感受存在，GAP，指标刷很高，人眼观感不佳，用GAN可缓解 落地的问题，SOTA模型运算量很(上百G Flops)，但实际不可能这么用</li><li>主要是为人眼服务，缺乏与High-level之间的联系</li></ul><hr><p>High-level任务：分类，检测，分割等。一般公开训练数据都是高品质的图像，当送入降质图像时，性能会有下降，即使网络已经经过大量的数据增强（形状，亮度，色度等变换）</p><p>真实应用场景是不可能像训练集那样完美的，采集图像的过程中会面临各种降质问题，需要两者来结合。简单来说，结合的方式分为以下几种</p><ul><li>直接在降质图像上fine-tuning</li><li>先经过low-level的增强网络，再送入High-level的模型，两者分开训练</li><li>将增强网络和高层模型（如分类）联合训练 ———————————————— 版权声明：本文为CSDN博主「WTHunt」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/qq_20880415/article/details/117225213</li></ul></blockquote>',12);function v(w,k){const t=l("ExternalLinkIcon");return r(),o("div",null,[h,e("blockquote",null,[d,e("p",null,[e("a",m,[i("Deblurring via Stochastic Refinement | Papers With Code"),n(t)])]),u]),g,p,_,e("blockquote",null,[e("p",null,[e("a",b,[i("论文阅读笔记之——《The Perception-Distortion Tradeoff》_gwpscut的博客-CSDN博客"),n(t)])])]),f])}const x=a(c,[["render",v],["__file","Deblurring-via-Stochastic-Refinement.html.vue"]]);export{x as default};
