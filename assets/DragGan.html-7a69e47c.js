import{_ as e,o as a,c as t,e as i}from"./app-04b0d2b0.js";const n={},r=i('<h1 id="drag-gan" tabindex="-1"><a class="header-anchor" href="#drag-gan" aria-hidden="true">#</a> Drag GAN</h1><p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20230610121650716.png" alt="image-20230610121650716"></p><img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20230610121706201.png" alt="image-20230610121706201" style="zoom:50%;"><h2 id="motion-supervision" tabindex="-1"><a class="header-anchor" href="#motion-supervision" aria-hidden="true">#</a> Motion Supervision</h2><p>GAN 生成的中间 feature 具有很强的语义性</p><p>Handle Point</p><p>Target Point</p><blockquote><p>如何监督 GAN 生成图像的点运动之前还没有太多探索。在这项工作中，我们提出了一种不依赖于任何额外神经网络的运动监督损失。关键思想是生成器的中间特征非常有辨别力，因此简单的损失就足以监督运动。具体来说，我们考虑了 StyleGAN2 第 6 个块之后的特征图 F，由于分辨率和判别力之间的良好权衡，它在所有特征中表现最好。我们通过双线性插值调整 F 的大小，使其具有与最终图像相同的分辨率。</p></blockquote><h2 id="point-tracking" tabindex="-1"><a class="header-anchor" href="#point-tracking" aria-hidden="true">#</a> Point Tracking</h2><blockquote><p>The insight is that the discriminative features of GANs well capture dense correspondence and thus tracking can be effectively performed via nearest neighbor search in a feature patch.</p></blockquote><p>更新 handle point</p>',11),o=[r];function c(s,h){return a(),t("div",null,o)}const p=e(n,[["render",c],["__file","DragGan.html.vue"]]);export{p as default};
