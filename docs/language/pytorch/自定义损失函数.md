---
sidebar: auto
---

# 自定义损失函数

## 1. 通过nn.Module类来实现自定义的损失函数

鉴于前面所说的，损失函数的本质也就是“对输入进行函数运算，得到一个输出”，所以我们可以像定义层一样自定义一个损失函数，比如我自己定义一个 MSE 损失函数，代码如下：

```python
class My_loss(nn.Module):
    def __init__(self):
        super().__init__()   #没有需要保存的参数和状态信息
        
    def forward(self, x, y):  # 定义前向的函数运算即可
        return torch.mean(torch.pow((x - y), 2))
```



::: tip

```
pytorch TypeError: __init__() takes 1 positional argument but 3 were given
```

在自己编写loss函数Myloss_for_neg后，调用时出现问题。

原因是需要**初始化**，即分两步：

```python
loss_fun = My_loss()
loss = My_loss(outputs, label)
```
类似于模型初始化
:::




## 2. 通过直接定义函数来完成



自定义类中，其实最终调用还是forward实现，同时`nn.Module`还要维护一些其他变量和状态。不如直接自定义loss函数实现：

> \# 直接定义函数 ， 不需要维护参数，梯度等信息
>
> \# 注意所有的数学操作需要使用 tensor 完成。

```python
def my_mse_loss(x, y):
    return torch.mean(torch.pow((x - y), 2))
```

`nn.functional` 里面定义了一些常见的函数，当然也包括一些常见的损失函数







> https://blog.csdn.net/qq_27825451/article/details/95165265
