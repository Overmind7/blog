# 2024.1.2 组会

## OneFormer3D

> CVPR 2023
>
> [LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs | Papers With Code](https://paperswithcode.com/paper/scaling-up-kernels-in-3d-cnns)



**摘要**：对于3D点云的语义分割、实例分割和全景分割已经分别使用了特定设计的任务模型进行了研究。因此，所有分割任务的相似性和它们之间的隐含关系并未得到有效利用。本文提出了一个统一、简单而有效的模型，共同解决了所有这些任务。该模型被命名为OneFormer3D，使用一组可学习的核心一致地执行实例和语义分割，其中每个核心负责为实例或语义类别生成掩码。这些核心通过一个基于transformer的解码器进行训练，其中统一的实例和语义查询作为输入传递。这样的设计使得能够在单次运行中端到端地训练模型，从而在同时实现所有三个分割任务的最佳性能。具体而言，我们的OneFormer3D在ScanNet测试排行榜中获得了第一名，并取得了新的最先进水平（+2.1 mAP50）。我们还展示了在ScanNet（+21 PQ）、ScanNet200（+3.8 mAP50）和S3DIS（+0.8 mIoU）数据集的语义分割、实例分割和全景分割方面的最先进结果。

### 解决的问题：

该论文要解决的问题是点云分割的问题，即如何将三维点云中的每个点分配到不同的语义或实例类别，从而实现对点云的理解和分析。点云分割是三维计算机视觉中的一个重要和具有挑战性的任务，它有着广泛的应用，如机器人导航、自动驾驶、增强现实等。点云分割的难点主要有以下几个方面：

1. 点云的表示方式多样，如稀疏体素、八叉树和点云，每种表示方式都有其优缺点，如何设计一个通用的模型，可以适应不同的点云表示，是一个关键的问题。
2. 点云的数据量大，且具有不规则和无序的特点，如何有效地处理点云的数据结构，提取点云的特征，是一个核心的问题。
3. 点云的分辨率和密度不均匀，且受到噪声和遮挡的影响，如何提高点云分割的鲁棒性和精度，是一个实际的问题。

该论文的目标是提出一个基于Transformer的模型，可以统一处理不同的点云表示，利用自注意力机制和跨注意力机制，捕捉点云的局部和全局上下文信息，同时引入一个动态的点云采样模块，可以根据点云的密度和复杂度，自适应地调整采样率，从而解决点云分割的问题。

### 主要贡献：

1. 它设计了一个通用的点云编码器，可以将不同的点云表示转换为一致的特征向量，从而实现跨表示的点云分割。
2. 它提出了一个基于Transformer的点云解码器，可以利用自注意力机制和跨注意力机制，有效地捕捉点云的局部和全局上下文信息。
3. 它引入了一个动态的点云采样模块，可以根据点云的密度和复杂度，自适应地调整采样率，从而提高模型的效率和鲁棒性。
4. 它在多个点云分割的数据集上进行了实验，包括S3DIS、ScanNetv2、ShapeNetPart和PartNet，并在所有数据集上取得了最先进的性能，证明了其模型的优越性和通用性。



### 架构

![image-20240104135438667](https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104135438667.png)

> OneFormer3D 框架基于 SPFormer（蓝色），但具有许多改进（红色）。一旦获得 3D 点云作为输入，我们训练的模型就可以解决 3D 实例、3D 语义和 3D 全景分割任务。虚线描绘了仅在训练期间应用的组件。

- First, a sparse 3D U-net extracts point-wise features
- Then, these features pass through a flexible pooling, that obtains superpoint features through simply averaging features of points in a superpoint. Superpoint features serve as keys and values for a transformer decoder (Sec. 3.2), that also accepts learnable semantic and instance queries as inputs. 
- The decoder captures superpoints information via a cross-attention mechanism, and outputs a set of learned kernels, each representing a single object mask of an instance identity (from an instance query) or a semantic region (from a semantic query. 
- A disentangled matching strategy is adopted to train instance kernels in an end-to-end manner (Sec. 3.3). As a result, a trained OneFormer3D can seamlessly solve semantic, instance, and panoptic segmentation (Sec. 3.4).
- 然后，这些特征通过flexible pooling灵活的池化，通过简单地平均超点中点的特征来获得Superpoint  feature超点特征。 Superpoint 特征充当transformer解码器的key和value（第 3.2 节），它也接受可学习的语义和实例queries作为输入。
- 解码器通过交叉注意机制捕获超点信息，并输出一组学习内核，每个内核代表实例身份（来自实例查询）或语义区域（来自语义查询）的单个对象掩码。
- 解缠结匹配策略采用端到端的方式训练实例内核（第 3.3 节）。因此，经过训练的 OneFormer3D 可以无缝解决语义、实例和全景分割问题（第 3.4 节）。



#### Sparse 3D U-Net.

假设输入点云包含N个点，则输入可以表示为$P \in R^{N \times 6}$。每个 3D 点都用三种颜色 r、g、b 和三个坐标 x、y、z 进行参数化。按照[6]，我们对点云进行体素化，并使用由稀疏 3D 卷积组成的类似 U-Net 的主干来提取逐点特征

#### Query Decoder

查询解码器将 $K_{ins} + K_{sem} $查询作为输入，并将其转换为 $K_{ins} + K_{sem}$ 内核。然后，超点特征与这些内核进行卷积，分别生成 $K_{ins}$ 实例和 $K_{sem}$ 语义掩码。

> Semantic queries语义查询是随机初始化的，与现有的 3D 实例分割方法相同?
>
> 通过交叉注意力学习

#### Query selection

最先进的 2D 对象检测和 2D 实例分割方法 [19,45,50] 使用高级策略初始化查询，通常称为查询选择。具体来说，输入查询使用来自转换器编码器的特征进行初始化，并根据对象分数进行采样。该分数是由同一模型估计的，该模型由训练期间额外的客观性损失引导。事实证明，所描述的技术可以加快训练速度，同时共同提高整体准确性。然而，据我们所知，类似的方法从未应用于 3D 对象检测或 3D 分割。

因此，我们的目标是通过适用于 3D 数据的查询选择的简化版本和非变换器编码器来缩小这一差距。特别是，我们在灵活池化后使用骨干特征初始化查询。通过查询选择，我们仅随机选择一半的初始化查询，以在训练期间进行额外的增强。在推理过程中，我们类似地初始化查询，但不过滤查询以保留所有输入信息。







## SPFormer

> [Superpoint Transformer for 3D Scene Instance Segmentation | Papers With Code](https://paperswithcode.com/paper/superpoint-transformer-for-3d-scene-instance)
>
> Superpoint Transformer for 3D Scene Instance Segmentation
>
> AAAI 2023

### 摘要

大多数现有方法通过扩展用于 3D 对象检测或 3D 语义分割的模型来实现 3D 实例分割。然而，这些非直接方法有两个缺点：

1）不精确的边界框或不令人满意的语义预测限制了整个 3D 实例分割框架的性能。 

2）现有方法需要耗时的聚合中间步骤。

为了解决这些问题，本文提出了一种基于 Superpoint Transformer的新颖的端到端3D实例分割方法，命名为SPFormer。它将点云中的潜在特征分组为 Superpoint，并通过查询向量直接预测实例，而不依赖于对象检测或语义分割的结果。该框架的关键步骤是一种带有 Transformer 的新型查询解码器，它可以通过 superpoint 交叉注意机制捕获实例信息并生成实例的 Superpoint 掩码。通过基于 superpoint 掩码的二分匹配，SPFormer 可以实现无需中间聚合步骤的网络训练，从而加速网络。 ScanNetv2 和 S3DIS 基准的大量实验验证了我们的方法简洁而高效。值得注意的是，SPFormer 在 ScanNetv2 隐藏测试集上的 mAP 超过了最先进的方法 4.3%，同时保持了快速的推理速度（每帧 247 毫秒）

> 提出一个混合框架，避免缺点并同时从两种类型的方法中受益。两阶段端到端的 3D 实例分割方法：SPFormer。
> SPFormer 将点云中自下而上的潜在特征分组为超级点，并通过查询向量作为自上而下的管道提出实例。



### Method

![image-20240104142224787](https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104142224787.png)

> SPFormer的整体架构，包含两个阶段。在自下而上的分组阶段，稀疏3D U-net从输入点云P中提取逐点特征，然后超点池化层将同质相邻点分组为超点特征S。在自上而下的提议阶段，查询解码器为分为两个分支。实例分支通过 Transformer Decoder 获取查询向量特征 Z’。 mask 分支提取 mask-aware 特征 Smask。最后，预测头生成实例预测，并在训练/推理期间将它们输入到二分匹配或排名中。



#### Query Decoder

查询解码器由实例分支和掩码分支组成。

在掩模分支中，一个简单的多层感知器（MLP）旨在提取掩模感知特征$S_{mask}$。

实例分支由一系列 Transformer 解码器层组成。通过超点交叉注意力来解码可学习的查询向量。假设有 K 个可学习的查询向量。我们将每个 Transformer 解码器层的查询向量的特征预定义为  D 是嵌入维数



**考虑到 Superpoint 的无序性和数量的不确定性**，引入 Transformer 结构来处理变长输入。Superpoint 的潜在特征和可学习的查询向量被用作变压器解码器的输入。我们修改后的 Transformer 解码器层的详细架构如下图所示：

<img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104142507489.png" alt="image-20240104142507489" style="zoom: 50%;" />

::: warning

In addition, because the input is the potential features of superpoints, we empirically remove position embedding.

*《Masked-attention mask transformer for universal image segmentation》CVPR2022*

:::

查询向量在训练前随机初始化，每个点云的实例信息只能通过超点交叉注意力获得，因此，与标准解码器层相比，我们的 Transformer 解码器层交换了自注意力层和交叉注意力层的顺序



经过线性投影后的 Superpoint 特征$S'$ ，来自上一层的查询向量 $Z_{l-1}$ 通过 Superpoint 交叉注意机制捕获上下文信息，可以表示为：

<img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104143304087.png" alt="image-20240104143304087" style="zoom:50%;" />

##### Shared Prediction Head

<img src="https://raw.githubusercontent.com/Overmind7/images/main/img/image-20240104150958286.png" alt="image-20240104150958286" style="zoom:50%;" />

使用来自实例分支的查询向量 $Z'$，我们使用两个独立的 MLP 来预测每个查询向量的分类 ，并使用 IoU 感知分数分别。

此外，提案的排名深刻地影响实例分割结果，

- 而在实践中，由于一对一的匹配方式，大多数提案会被视为背景，这导致提案质量排名的错位。
- 因此，我们设计了一个分数分支来估计预测的超点mask和gt-mask的 IoU，以补偿未对准misalignment.。
-  mask-aware features $S$​, directly multiply it by query vectors Z‘ followed a sigmoid function to generate superpoint masks prediction M‘







---------------------------------------------------------

## 稀疏卷积后端

构建一个稀疏卷积需要满足哪些要求:

1. 减少不必要的运算量。

2) 满足特征的稀疏性，并且在保证稀疏性的同时维护特征的空间不变性。

### 1. MinkEngine

$C = \left[ \begin{matrix} x_1 & y_1 & z_1 & b_1\\  & : & : &  \\ x_N & y_N & z_N & b_N \end{matrix} \right]$,$F = \left[ \begin{matrix} f_1^T \\ :  \\ f_N^T \end{matrix} \right]$

其中 (x,y,z) 表示点云的坐标， b 表示 属于batch中的哪个点云 (MinkowskiEngine也是把点云组织成batch进行训练)， $N$ 表示1个batch中所有点的数量， $f^i_n$ 表示第 i 个点的特征，可以是1维或者3维或者其它维度的。

#### Sparse Tensor Quantization

数据处理以生成稀疏张量

将所有坐标转换为哈希键，并找到所有唯一的哈希键标签对以消除冲突。

#### Generalized Sparse Convolution

- 根据输入坐标 Cin（Eq.3）生成输出坐标 Cout。

- 使用指定的内核映射将输入与内核进行卷积

####  Pooling



#### Non-spatial Funtions





### 2. SpConv

> [traveller59/spconv: Spatial Sparse Convolution Library (github.com)](https://github.com/traveller59/spconv)
>
> [spConv稀疏卷积 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/467167809?utm_id=0)

::: tip 什么是（submanifold）子流形？

> We use the term 'submanifold' to refer to input data that is sparse because it has a lower effective dimension than the space in which it lives, for example a one-dimensional curve in 2+ dimensional space, or a two-dimensional surface in 3+ dimensional space.

我们使用术语“子流形”来表示输入数据是稀疏的，因为它的有效维数低于它所在的空间，例如二维空间中的一维曲线，或三维空间中的二维曲面。

:::

#### 建立输入哈希表

![img](https://raw.githubusercontent.com/Overmind7/images/main/img/v2-7f35a88cbb6169a64e5e2b1fa9f1f477_1440w.png)

首先，稀疏卷积操作会将输入转化为Hash_in这张输入哈希表，hash_in表示着**activate输入**的标志（也就是说对应的这个稀疏输入是需要被计算的）。

对于P1点而言，在hash_in中对应了v=0 key=(2,1)。其对应的输出tensor中与P1有关的像素点为A1的六个位置那么将这些点视作作为P_out。以此类推P2也会拥有一系列P2_out的点。将这些Pout点合并后可以获得Hash_out表。

构建hash表的最重要原因是我们在前面提到的在完成稀疏卷积后为了防止稀疏特征的塌缩失去几何特征的表示能力，这里将Tensor的坐标与序号进行对应，方便卷积计算好数值之后将其放回原本tensor的位置。

#### 建立RuleBook

在第一步中，我们成功的建立了输入和输出的哈希表。这两个表分别将输入和输出的Tensor坐标映射到了序号，但是这两张表之间的序号是不统一的现在需要额外构建一张rulebook表将输入和输出这两张表对应起来。

![img](https://raw.githubusercontent.com/Overmind7/images/main/img/v2-d81a7da1dc790606281f1452fa5056b0_1440w.png)



上图显示了构建Rulebook的整体流程，其中分为两个主要部分。

第一，将Pout转化到GetOffset(Pin, P)；

第二，从GetOffSet(Pin, P)转化到Rulebook。

- 首先来看如何构建GetOffset（Pin, P）这个函数。假如以Pout(0,0)为例，在这个橙色的窗口中只有右侧P1位置非零，其余位置均为零。那么这次卷积操作只需要通过这个位置的卷积权重和输入值计算得到。P1位置对应到卷积核中的位置就是（1，0）。我们把这个（1，0）放入GetOffset()结果中。

- 将GetOffset()进一步得到Rulebook
    - 在上一步中我们根据Pin与Pout获得GetOffset()，那么这个获得的方法就可以总结成Rulebook。我们可以看到Rulebook中第一列为上一步记录的卷积核权重位置，第三列为输入像素值的输入序号，第四列为卷积结果对应的输出序号,count为各个卷积权重的数量统计。

稀疏卷积在GPU中的运算是通过查询Rulebook实现的，以*Rulebook*第一行红色方框为例，首先通过（-1，-1）找到卷积核权重F0；其次，根据输入像素序号，查找输入哈希表找到对应的tensor向量（0.1，0.1，0.1）

![img](https://raw.githubusercontent.com/Overmind7/images/main/img/v2-8b3177a25ee2a768a6d57e626aed7ed1_1440w.png)

### 3. TorchSparse

> [TorchSparse: Efficient Point Cloud Inference Engine | Papers With Code](https://paperswithcode.com/paper/torchsparse-efficient-point-cloud-inference)
>
> [TorchSparse++: Efficient Training and Inference Framework for Sparse Convolution on GPUs | Papers With Code](https://paperswithcode.com/paper/torchsparse-efficient-training-and-inference)

TorchSparse的优化策略包括：

1. 采用自适应的矩阵乘法分组，提高计算的规则性；
2. 采用量化，向量化和局部性感知的内存访问，减少数据移动的开销；
3.  采用内核融合，减少映射操作的延迟

TorchSparse++:

1. 提出了一个稀疏核生成器，可以快速生成高性能的稀疏卷积核，降低了工程复杂度；
2. 设计了一个稀疏自动调优器，可以在扩大的设计空间中搜索最佳的数据流配置，适应不同的训练和推理工作负载。